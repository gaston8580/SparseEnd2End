Sparse4D(
  (img_backbone): ResNet(
    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (3): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (4): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (5): Bottleneck(
        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): ResLayer(
      (0): Bottleneck(
        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (2): Bottleneck(
        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  (img_neck): FPN(
    (lateral_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
      )
    )
    (fpn_convs): ModuleList(
      (0): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (1): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (2): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
      (3): ConvModule(
        (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  init_cfg={'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
  (head): Sparse4DHead(
    (instance_bank): InstanceBank(
      (anchor_handler): SparseBox3DKeyPointsGenerator()
    )
    (anchor_encoder): SparseBox3DEncoder(
      (pos_fc): Sequential(
        (0): Linear(in_features=3, out_features=128, bias=True)
        (1): ReLU(inplace=True)
        (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (3): Linear(in_features=128, out_features=128, bias=True)
        (4): ReLU(inplace=True)
        (5): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (6): Linear(in_features=128, out_features=128, bias=True)
        (7): ReLU(inplace=True)
        (8): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
        (9): Linear(in_features=128, out_features=128, bias=True)
        (10): ReLU(inplace=True)
        (11): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
      )
      (size_fc): Sequential(
        (0): Linear(in_features=3, out_features=32, bias=True)
        (1): ReLU(inplace=True)
        (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (3): Linear(in_features=32, out_features=32, bias=True)
        (4): ReLU(inplace=True)
        (5): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (6): Linear(in_features=32, out_features=32, bias=True)
        (7): ReLU(inplace=True)
        (8): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (9): Linear(in_features=32, out_features=32, bias=True)
        (10): ReLU(inplace=True)
        (11): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
      )
      (yaw_fc): Sequential(
        (0): Linear(in_features=2, out_features=32, bias=True)
        (1): ReLU(inplace=True)
        (2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (3): Linear(in_features=32, out_features=32, bias=True)
        (4): ReLU(inplace=True)
        (5): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (6): Linear(in_features=32, out_features=32, bias=True)
        (7): ReLU(inplace=True)
        (8): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
        (9): Linear(in_features=32, out_features=32, bias=True)
        (10): ReLU(inplace=True)
        (11): LayerNorm((32,), eps=1e-05, elementwise_affine=True)
      )
      (vel_fc): Sequential(
        (0): Linear(in_features=3, out_features=64, bias=True)
        (1): ReLU(inplace=True)
        (2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (3): Linear(in_features=64, out_features=64, bias=True)
        (4): ReLU(inplace=True)
        (5): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (6): Linear(in_features=64, out_features=64, bias=True)
        (7): ReLU(inplace=True)
        (8): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
        (9): Linear(in_features=64, out_features=64, bias=True)
        (10): ReLU(inplace=True)
        (11): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
      )
    )
    (loss_cls): FocalLoss()
    (loss_reg): SparseBox3DLoss(
      (loss_box): L1Loss()
      (loss_cns): CrossEntropyLoss(avg_non_ignore=False)
      (loss_yns): GaussianFocalLoss()
    )
    (layers): ModuleList(
      (0): DeformableAttentionAggr(
        (proj_drop): Dropout(p=0.0, inplace=False)
        (kps_generator): SparseBox3DKeyPointsGenerator(
          (learnable_fc): Linear(in_features=256, out_features=18, bias=True)
        )
        (output_proj): Linear(in_features=256, out_features=256, bias=True)
        (camera_encoder): Sequential(
          (0): Linear(in_features=12, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (weights_fc): Linear(in_features=256, out_features=416, bias=True)
      )
      (1): AsymmetricFFN(
        (activate): ReLU(inplace=True)
        (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (layers): Sequential(
          (0): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): ReLU(inplace=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (1): Linear(in_features=1024, out_features=256, bias=True)
          (2): Dropout(p=0.1, inplace=False)
        )
        (dropout_layer): Identity()
        (identity_fc): Linear(in_features=512, out_features=256, bias=True)
      )
      (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (3): SparseBox3DRefinementModule(
        (layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
          (6): ReLU(inplace=True)
          (7): Linear(in_features=256, out_features=256, bias=True)
          (8): ReLU(inplace=True)
          (9): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (10): Linear(in_features=256, out_features=11, bias=True)
          (11): Scale()
        )
        (cls_layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (6): Linear(in_features=256, out_features=10, bias=True)
        )
        (quality_layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (6): Linear(in_features=256, out_features=2, bias=True)
        )
      )
      (4): MultiheadAttention(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (proj_drop): Dropout(p=0.0, inplace=False)
        (dropout_layer): Dropout(p=0.1, inplace=False)
      )
      (5): MultiheadAttention(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (proj_drop): Dropout(p=0.0, inplace=False)
        (dropout_layer): Dropout(p=0.1, inplace=False)
      )
      (6): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (7): DeformableAttentionAggr(
        (proj_drop): Dropout(p=0.0, inplace=False)
        (kps_generator): SparseBox3DKeyPointsGenerator(
          (learnable_fc): Linear(in_features=256, out_features=18, bias=True)
        )
        (output_proj): Linear(in_features=256, out_features=256, bias=True)
        (camera_encoder): Sequential(
          (0): Linear(in_features=12, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (weights_fc): Linear(in_features=256, out_features=416, bias=True)
      )
      (8): AsymmetricFFN(
        (activate): ReLU(inplace=True)
        (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (layers): Sequential(
          (0): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): ReLU(inplace=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (1): Linear(in_features=1024, out_features=256, bias=True)
          (2): Dropout(p=0.1, inplace=False)
        )
        (dropout_layer): Identity()
        (identity_fc): Linear(in_features=512, out_features=256, bias=True)
      )
      (9): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (10): SparseBox3DRefinementModule(
        (layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
          (6): ReLU(inplace=True)
          (7): Linear(in_features=256, out_features=256, bias=True)
          (8): ReLU(inplace=True)
          (9): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (10): Linear(in_features=256, out_features=11, bias=True)
          (11): Scale()
        )
        (cls_layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (6): Linear(in_features=256, out_features=10, bias=True)
        )
        (quality_layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (6): Linear(in_features=256, out_features=2, bias=True)
        )
      )
      (11): MultiheadAttention(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (proj_drop): Dropout(p=0.0, inplace=False)
        (dropout_layer): Dropout(p=0.1, inplace=False)
      )
      (12): MultiheadAttention(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (proj_drop): Dropout(p=0.0, inplace=False)
        (dropout_layer): Dropout(p=0.1, inplace=False)
      )
      (13): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (14): DeformableAttentionAggr(
        (proj_drop): Dropout(p=0.0, inplace=False)
        (kps_generator): SparseBox3DKeyPointsGenerator(
          (learnable_fc): Linear(in_features=256, out_features=18, bias=True)
        )
        (output_proj): Linear(in_features=256, out_features=256, bias=True)
        (camera_encoder): Sequential(
          (0): Linear(in_features=12, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (weights_fc): Linear(in_features=256, out_features=416, bias=True)
      )
      (15): AsymmetricFFN(
        (activate): ReLU(inplace=True)
        (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (layers): Sequential(
          (0): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): ReLU(inplace=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (1): Linear(in_features=1024, out_features=256, bias=True)
          (2): Dropout(p=0.1, inplace=False)
        )
        (dropout_layer): Identity()
        (identity_fc): Linear(in_features=512, out_features=256, bias=True)
      )
      (16): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (17): SparseBox3DRefinementModule(
        (layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
          (6): ReLU(inplace=True)
          (7): Linear(in_features=256, out_features=256, bias=True)
          (8): ReLU(inplace=True)
          (9): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (10): Linear(in_features=256, out_features=11, bias=True)
          (11): Scale()
        )
        (cls_layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (6): Linear(in_features=256, out_features=10, bias=True)
        )
        (quality_layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (6): Linear(in_features=256, out_features=2, bias=True)
        )
      )
      (18): MultiheadAttention(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (proj_drop): Dropout(p=0.0, inplace=False)
        (dropout_layer): Dropout(p=0.1, inplace=False)
      )
      (19): MultiheadAttention(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (proj_drop): Dropout(p=0.0, inplace=False)
        (dropout_layer): Dropout(p=0.1, inplace=False)
      )
      (20): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (21): DeformableAttentionAggr(
        (proj_drop): Dropout(p=0.0, inplace=False)
        (kps_generator): SparseBox3DKeyPointsGenerator(
          (learnable_fc): Linear(in_features=256, out_features=18, bias=True)
        )
        (output_proj): Linear(in_features=256, out_features=256, bias=True)
        (camera_encoder): Sequential(
          (0): Linear(in_features=12, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (weights_fc): Linear(in_features=256, out_features=416, bias=True)
      )
      (22): AsymmetricFFN(
        (activate): ReLU(inplace=True)
        (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (layers): Sequential(
          (0): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): ReLU(inplace=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (1): Linear(in_features=1024, out_features=256, bias=True)
          (2): Dropout(p=0.1, inplace=False)
        )
        (dropout_layer): Identity()
        (identity_fc): Linear(in_features=512, out_features=256, bias=True)
      )
      (23): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (24): SparseBox3DRefinementModule(
        (layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
          (6): ReLU(inplace=True)
          (7): Linear(in_features=256, out_features=256, bias=True)
          (8): ReLU(inplace=True)
          (9): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (10): Linear(in_features=256, out_features=11, bias=True)
          (11): Scale()
        )
        (cls_layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (6): Linear(in_features=256, out_features=10, bias=True)
        )
        (quality_layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (6): Linear(in_features=256, out_features=2, bias=True)
        )
      )
      (25): MultiheadAttention(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (proj_drop): Dropout(p=0.0, inplace=False)
        (dropout_layer): Dropout(p=0.1, inplace=False)
      )
      (26): MultiheadAttention(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (proj_drop): Dropout(p=0.0, inplace=False)
        (dropout_layer): Dropout(p=0.1, inplace=False)
      )
      (27): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (28): DeformableAttentionAggr(
        (proj_drop): Dropout(p=0.0, inplace=False)
        (kps_generator): SparseBox3DKeyPointsGenerator(
          (learnable_fc): Linear(in_features=256, out_features=18, bias=True)
        )
        (output_proj): Linear(in_features=256, out_features=256, bias=True)
        (camera_encoder): Sequential(
          (0): Linear(in_features=12, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (weights_fc): Linear(in_features=256, out_features=416, bias=True)
      )
      (29): AsymmetricFFN(
        (activate): ReLU(inplace=True)
        (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (layers): Sequential(
          (0): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): ReLU(inplace=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (1): Linear(in_features=1024, out_features=256, bias=True)
          (2): Dropout(p=0.1, inplace=False)
        )
        (dropout_layer): Identity()
        (identity_fc): Linear(in_features=512, out_features=256, bias=True)
      )
      (30): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (31): SparseBox3DRefinementModule(
        (layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
          (6): ReLU(inplace=True)
          (7): Linear(in_features=256, out_features=256, bias=True)
          (8): ReLU(inplace=True)
          (9): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (10): Linear(in_features=256, out_features=11, bias=True)
          (11): Scale()
        )
        (cls_layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (6): Linear(in_features=256, out_features=10, bias=True)
        )
        (quality_layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (6): Linear(in_features=256, out_features=2, bias=True)
        )
      )
      (32): MultiheadAttention(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (proj_drop): Dropout(p=0.0, inplace=False)
        (dropout_layer): Dropout(p=0.1, inplace=False)
      )
      (33): MultiheadAttention(
        (attn): MultiheadAttention(
          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
        )
        (proj_drop): Dropout(p=0.0, inplace=False)
        (dropout_layer): Dropout(p=0.1, inplace=False)
      )
      (34): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (35): DeformableAttentionAggr(
        (proj_drop): Dropout(p=0.0, inplace=False)
        (kps_generator): SparseBox3DKeyPointsGenerator(
          (learnable_fc): Linear(in_features=256, out_features=18, bias=True)
        )
        (output_proj): Linear(in_features=256, out_features=256, bias=True)
        (camera_encoder): Sequential(
          (0): Linear(in_features=12, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        )
        (weights_fc): Linear(in_features=256, out_features=416, bias=True)
      )
      (36): AsymmetricFFN(
        (activate): ReLU(inplace=True)
        (pre_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        (layers): Sequential(
          (0): Sequential(
            (0): Linear(in_features=512, out_features=1024, bias=True)
            (1): ReLU(inplace=True)
            (2): Dropout(p=0.1, inplace=False)
          )
          (1): Linear(in_features=1024, out_features=256, bias=True)
          (2): Dropout(p=0.1, inplace=False)
        )
        (dropout_layer): Identity()
        (identity_fc): Linear(in_features=512, out_features=256, bias=True)
      )
      (37): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
      (38): SparseBox3DRefinementModule(
        (layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): Linear(in_features=256, out_features=256, bias=True)
          (3): ReLU(inplace=True)
          (4): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (5): Linear(in_features=256, out_features=256, bias=True)
          (6): ReLU(inplace=True)
          (7): Linear(in_features=256, out_features=256, bias=True)
          (8): ReLU(inplace=True)
          (9): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (10): Linear(in_features=256, out_features=11, bias=True)
          (11): Scale()
        )
        (cls_layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (6): Linear(in_features=256, out_features=10, bias=True)
        )
        (quality_layers): Sequential(
          (0): Linear(in_features=256, out_features=256, bias=True)
          (1): ReLU(inplace=True)
          (2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (3): Linear(in_features=256, out_features=256, bias=True)
          (4): ReLU(inplace=True)
          (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
          (6): Linear(in_features=256, out_features=2, bias=True)
        )
      )
    )
    (fc_before): Linear(in_features=256, out_features=512, bias=False)
    (fc_after): Linear(in_features=512, out_features=256, bias=False)
  )
  (depth_branch): DenseDepthNet(
    (depth_layers): ModuleList(
      (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))
    )
  )
  (grid_mask): GridMask()
)